---
title: "Parte B"
output: html_document
author: "Micaela Del Longo @MicaKil"
---

# Librerías

```{r}
library(dplyr)
library(ggplot2)
library(lattice)
library(caret)
library(randomForest)
```

# Separación de Datos

```{r}
data <- read.csv("data/arbolado-mza-dataset.csv")
data$inclinacion_peligrosa <- factor(data$inclinacion_peligrosa)

# remueve columnas innecesarias
data$ultima_modificacion <- NULL
data$area_seccion <- NULL
data$nombre_seccion <- NULL

data_inclinacion_peligrosa_0 <- data %>% dplyr::filter(inclinacion_peligrosa == 0)
data_inclinacion_peligrosa_1 <- data %>% dplyr::filter(inclinacion_peligrosa == 1)

# undersampling
set.seed(2023)
indeces_inclinacion_peligrosa_0 <- caret::createDataPartition(data_inclinacion_peligrosa_0$inclinacion_peligrosa, p = 0.125, list = FALSE)
undersampled_data <- data_inclinacion_peligrosa_0[indeces_inclinacion_peligrosa_0, ]

# merge
balanced_data <- rbind(data_inclinacion_peligrosa_1, undersampled_data)  # bind rows
balanced_data <- balanced_data[order(balanced_data$id), ]  # ordena por id

# split by 80/20
set.seed(2023)
indeces_train <- caret::createDataPartition(balanced_data$inclinacion_peligrosa, p = 0.8, list = FALSE)
train_data <- balanced_data[indeces_train, ]
validation_data <- balanced_data[-indeces_train, ]

train_1 <- train_data %>% dplyr::filter(inclinacion_peligrosa == 1) %>% nrow()
rows_train <- nrow(train_data)
percent_train <- train_1 / rows_train * 100
validation_1 <- validation_data %>% dplyr::filter(inclinacion_peligrosa == 1) %>% nrow()
rows_validation <- nrow(validation_data)
percent_validation <- validation_1 / rows_validation * 100

# guardar
write.csv(train_data, "data_tests/arbolado-mendoza-dataset-train.csv", row.names = FALSE)
write.csv(validation_data, "data_tests/arbolado-mendoza-dataset-validation.csv", row.names = FALSE)
```

# Análisis exploratorio

> In **count encoding** we replace the categories by the count of the observations that show that category in the dataset.
> Similarly, we can replace the category by the **frequency** -or percentage- of observations in the dataset. That is, if
> 10 of our 100 observations show the colour blue, we would replace blue by 10 if doing count encoding, or by 0.1 if
> replacing by the frequency. These techniques capture the representation of each label in a dataset, but the encoding
> may not necessarily be predictive of the outcome.
>
> This approach is heavily used in Kaggle competitions, wherein we replace each label of the categorical variable by
> the count, this is the amount of times each label appears in the dataset. Or the frequency, this is the percentage
> of observations within that category. The two methods are equivalent.

## Peligrosidad Encoding

```{r}
peligrosidad_encoding <- function(data, column, new_column) {
    peligrosidad <- data %>%
        dplyr::group_by(!!sym(column)) %>%
        dplyr::summarize(peligrosa_count = sum(inclinacion_peligrosa == 1), total_count = n()) %>%
        dplyr::mutate({{new_column}} := peligrosa_count / total_count)

    return(peligrosidad)
}

# p <- peligrosidad_encoding(train_data, "especie", "peligrosidad_especie")
# p
```

## Peligrosidad por Especie

```{r}
# especies_peligrosas <- train_data %>%
#     dplyr::group_by(especie) %>%  # agrupa por especie
#     dplyr::summarize(peligrosa_count = sum(inclinacion_peligrosa == 1), total_count = n()) %>%
#     dplyr::mutate(peligrosidad_especie = peligrosa_count / total_count)

especies_peligrosas <- peligrosidad_encoding(train_data, "especie", "peligrosidad_especie")
```

### Gráfico de Peligrosidad por Especie

```{r}
ggplot(especies_peligrosas,
       aes(x = reorder(especie, -peligrosidad_especie),
           y = peligrosidad_especie,
           fill = reorder(especie, -peligrosidad_especie))) +
    geom_bar(stat = "identity") +
    scale_fill_manual(values = rainbow(length(unique(especies_peligrosas$especie)))) +
    labs(x = "Especie del Arbol", y = "Proporcion de Inclinacion Peligrosa") +
    ggtitle("Peligrosidad por Especie de Arbol") +
    theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

### Reemplazo de Columna de Especie por Peligrosidad por Especie

```{r}
train_data <- train_data %>%
    left_join(especies_peligrosas %>% select(especie, peligrosidad_especie), by = "especie")

validation_data <- validation_data %>%
    left_join(especies_peligrosas %>% select(especie, peligrosidad_especie), by = "especie")

train_data$especie <- NULL
validation_data$especie <- NULL
train_data
```

## Peligrosidad por Diámetro

```{r}
diametro_peligroso <- peligrosidad_encoding(train_data, "diametro_tronco", "peligrosidad_diametro")
print(diametro_peligroso)
```

```{r}
ggplot(diametro_peligroso,
       aes(x = reorder(diametro_tronco, -peligrosidad_diametro),
           y = peligrosidad_diametro,
           fill = reorder(diametro_tronco, -peligrosidad_diametro))) +
    geom_bar(stat = "identity") +
    scale_fill_manual(values = rainbow(length(unique(diametro_peligroso$diametro_tronco)))) +
    labs(x = "Diametro del Arbol", y = "Proporcion de Inclinacion Peligrosa") +
    ggtitle("Peligrosidad por Diametro de Arbol") +
    theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

```{r}
train_data <- train_data %>%
    left_join(diametro_peligroso %>% select(diametro_tronco, peligrosidad_diametro), by = "diametro_tronco")

validation_data <- validation_data %>%
    left_join(diametro_peligroso %>% select(diametro_tronco, peligrosidad_diametro), by = "diametro_tronco")

train_data$diametro_tronco <- NULL
validation_data$diametro_tronco <- NULL
validation_data
```

## Peligrosidad por Altura

```{r}
altura_peligrosa <- peligrosidad_encoding(train_data, "altura", "peligrosidad_altura")
print(altura_peligrosa)
```

```{r}
ggplot(altura_peligrosa,
       aes(x = reorder(altura, -peligrosidad_altura),
           y = peligrosidad_altura,
           fill = reorder(altura, -peligrosidad_altura))) +
    geom_bar(stat = "identity") +
    scale_fill_manual(values = rainbow(length(unique(altura_peligrosa$altura)))) +
    labs(x = "Altura del Arbol", y = "Proporcion de Inclinacion Peligrosa") +
    ggtitle("Peligrosidad por Altura de Arbol") +
    theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

```{r}
train_data <- train_data %>%
	left_join(altura_peligrosa %>% select(altura, peligrosidad_altura), by = "altura")

validation_data <- validation_data %>%
	left_join(altura_peligrosa %>% select(altura, peligrosidad_altura), by = "altura")

train_data$altura <- NULL
validation_data$altura <- NULL
validation_data
```

# Recursive Feature Elimination

```{r}
# RFE is popular because it is easy to configure and use and because it is effective at selecting those features (columns) in a training dataset that are more or most relevant in predicting the target variable.
rfecrtl <- caret::rfeControl(functions=rfFuncs, method="cv", number=10, verbose=TRUE, allowParallel=TRUE)
results <- caret::rfe(inclinacion_peligrosa ~ circ_tronco_cm + lat + long + seccion + especie + peligrosidad_especie + peligrosidad_diametro,
                      data=train_data,
                      sizes=1:10,
                      rfeControl=rfecrtl)
predictors(results)
plot(results)
```

# Modelo

```{r}
rf <- randomForest(inclinacion_peligrosa ~ circ_tronco_cm + lat + long + seccion + peligrosidad_especie + peligrosidad_diametro + peligrosidad_altura,
                   data = train_data,
                   ntree = 1000
				   #mtry = 3,  # Number of variables randomly sampled at each split. Default values: for classification sqrt(p) and regression p/3
                   )
```

```{r}
rf
varImpPlot(rf)
```

# Predicción

```{r}
predictions <- predict(rf, validation_data)
confusion_matrix <- confusionMatrix(predictions, validation_data$inclinacion_peligrosa)
confusion_matrix
```

```{r}
predictions_numeric <- as.numeric(as.character(predictions)) # predictions es un factor, hay que pasarlo a numeric

result_dataset <- data.frame(id = validation_data$id, inclinacion_peligrosa = predictions_numeric)
```

```{r}
#write.csv(result_dataset, "data_tests/arbolado-mendoza-dataset-result.csv", row.names = FALSE)
```
