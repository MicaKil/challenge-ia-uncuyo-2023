---
title: "Parte A"
output: html_document
author: "Micaela Del Longo @MicaKil"
---

Antes de realizar un primer envío se deben realizar las siguientes actividades:

# Ejercicio 1

Dado el archivo arbolado-mendoza-dataset.csv, seleccionar de manera uniformemente aleatoria el 20% del conjunto de datos
y crear un nuevo archivo con el nombre de arbolado-mendoza-dataset-validation.csv y el 80% restante con el nombre de
arbolado-mendoza-dataset-train.csv

```{r}
data <- read.csv("data/arbolado-mza-dataset.csv")

num_filas <- nrow(data)

# define la proporción para dividir los datos (80% de entrenamiento, 20% de validación)
proporcion_entrenamiento <- 0.8

# calcula el número de filas para los datos de entrenamiento y validación
num_entrenamiento <- round(num_filas * proporcion_entrenamiento)
num_validacion <- num_filas - num_entrenamiento

# genera un conjunto de índices aleatorios sin reemplazo (por default replace=FALSE) para las filas de validación
indices_validacion <- sample(1:num_filas, num_validacion)

# divide los datos en conjuntos de entrenamiento y validación
datos_entrenamiento <- data[-indices_validacion, ]  # el operador "-" indica que se excluyen los índices de validación
datos_validacion <- data[indices_validacion, ]

# write.csv(datos_entrenamiento, "arbolado-mendoza-dataset-train.csv", row.names = FALSE)
# write.csv(datos_validacion, "arbolado-mendoza-dataset-validation.csv", row.names = FALSE)
```

# Ejercicio 2
A partir del archivo arbolado-mendoza-dataset-train.csv responder las siguientes preguntas:

1. ¿Cuál es la distribución de la clase inclinacion_peligrosa?
2. ¿Se puede considerar alguna sección más peligrosa que otra?
3. ¿Se puede considerar alguna especie más peligrosa que otra?

**IMPORTANTE:** para responder cada una de estas preguntas se deberá generar una visualización/gráfico que justifique la
respuesta.

```{r}
library(dplyr)
library(ggplot2)

data <- read.csv("data/arbolado-mendoza-dataset-train.csv")

```


## Pregunta 1: ¿Cuál es la distribución de la clase inclinacion_peligrosa?

```{r}
ggplot(data, aes(x = factor(inclinacion_peligrosa), fill = factor(inclinacion_peligrosa))) +
    geom_bar() +
    scale_fill_manual(values = c("blue", "red")) + # asigna colores a las barras
    labs(x = "Inclinacion Peligrosa", y = "Frecuencia") +
    ggtitle("Distribucion de la Clase Inclinacion Peligrosa")

# ggsave("pics/2_1_distribucion_inclinacion_peligrosa.png", plot = last_plot(), width = 6, height = 4)

```


## Pregunta 2: ¿Se puede considerar alguna sección más peligrosa que otra?

```{r}
# crea un nuevo conjunto de datos "secciones_peligrosas" con resumen de peligrosidad por sección
secciones_peligrosas <- data %>%
    group_by(seccion) %>%  # agrupar por sección
    # resumen de peligrosidad por sección -> total_count = n() calcula el número total de filas en cada grupo
    summarize(peligrosa_count = sum(inclinacion_peligrosa == 1), total_count = n()) %>%
    # mutate agrega una nueva columna peligrosidad la cual se calcula dividiendo peligrosa_count entre total_count
    mutate(peligrosidad = peligrosa_count / total_count)

ggplot(secciones_peligrosas, aes(x = factor(seccion), y = peligrosidad, fill = factor(seccion))) +
    geom_bar(stat = "identity") +  # representa las alturas de las barras tal como se proporcionan en los datos
    scale_fill_brewer(palette = "Set3") +
    labs(x = "Seccion Administrativa", y = "Proporcion de Inclinacion Peligrosa") +
    ggtitle("Peligrosidad por Seccion Administrativa")

#ggsave("pics/2_2_peligrosidad_secciones.png", plot = last_plot(), width = 8, height = 6)

nombre_secciones_peligrosas <- data %>%
    group_by(nombre_seccion) %>%
    # resumen de peligrosidad por sección -> total_count = n() calcula el número total de filas en cada grupo
    summarize(peligrosa_count = sum(inclinacion_peligrosa == 1), total_count = n()) %>%
    # mutate agrega una nueva columna peligrosidad la cual se calcula dividiendo peligrosa_count entre total_count
    mutate(peligrosidad = peligrosa_count / total_count)

ggplot(nombre_secciones_peligrosas, aes(x = factor(nombre_seccion), y = peligrosidad, fill = factor(nombre_seccion))) +
geom_bar(stat = "identity") +  # representa las alturas de las barras tal como se proporcionan en los datos
scale_fill_brewer(palette = "Set3") +
labs(x = "Nombre Seccion Administrativa", y = "Proporcion de Inclinacion Peligrosa") +
ggtitle("Peligrosidad por Seccion Administrativa (Nombre)") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))

#ggsave("pics/2_2_peligrosidad_nombre_secciones.png", plot = last_plot(), width = 8, height = 6)
```


## Pregunta 3: ¿Se puede considerar alguna especie más peligrosa que otra?

```{r}
# crea un nuevo conjunto de datos "especies_peligrosas" con resumen de peligrosidad por especie
especies_peligrosas <- data %>%
    group_by(especie) %>%  # agrupa por especie
    summarize(peligrosa_count = sum(inclinacion_peligrosa == 1), total_count = n()) %>%
    mutate(peligrosidad = peligrosa_count / total_count)

ggplot(especies_peligrosas, aes(x = reorder(especie, -peligrosidad), y = peligrosidad, fill = reorder(especie, -peligrosidad))) +
    geom_bar(stat = "identity") +
    scale_fill_manual(values = rainbow(length(unique(especies_peligrosas$especie)))) +
    labs(x = "Especie del Arbol", y = "Proporcion de Inclinacion Peligrosa") +
    ggtitle("Peligrosidad por Especie de Arbol") +
    theme(axis.text.x = element_text(angle = 90, hjust = 1))

#ggsave("pics/2_3_peligrosidad_especies.png", plot = last_plot(), width = 8, height = 6)

```


# Ejercicio 3

A partir del archivo arbolado-mendoza-dataset-train.csv:

## Ejercicio 3.1
Generar un histograma de frecuencia para la variable circ_tronco_cm. Probar con diferentes números de bins.

```{r}
# Cargar la biblioteca necesaria
library(ggplot2)
arbolado <- read.csv("data/arbolado-mendoza-dataset-train.csv")
```

```{r}
ggplot(arbolado, aes(x = circ_tronco_cm)) +
    geom_histogram(bins = 10, aes(fill = after_stat(count))) +
    scale_fill_gradient(low = "blue", high = "red") +
    labs(title = "Histograma de Circunferencia del Tronco (Bins = 10)", x = "Circunferencia del Tronco (cm)", y = "Frecuencia") +
    scale_x_continuous(breaks = seq(0, max(arbolado$circ_tronco_cm), by = 25))

# ggsave("pics/3_1_histograma_circ_tronco_bins_10.png", plot = last_plot(), width = 8, height = 6)
```

```{r}
ggplot(arbolado, aes(x = circ_tronco_cm)) +
    geom_histogram(bins = 20, aes(fill = after_stat(count))) +
    scale_fill_gradient(low = "blue", high = "red") +
    labs(title = "Histograma de Circunferencia del Tronco (Bins = 20)", x = "Circunferencia del Tronco (cm)", y = "Frecuencia") +
    scale_x_continuous(breaks = seq(0, max(arbolado$circ_tronco_cm), by = 25))

# ggsave("pics/3_1_histograma_circ_tronco_bins_20.png", plot = last_plot(), width = 8, height = 6)
```

```{r}
ggplot(arbolado, aes(x = circ_tronco_cm)) +
    geom_histogram(bins = 30, aes(fill = after_stat(count))) +
    scale_fill_gradient(low = "blue", high = "red") +
    labs(title = "Histograma de Circunferencia del Tronco (Bins = 30)", x = "Circunferencia del Tronco (cm)", y = "Frecuencia") +
    scale_x_continuous(breaks = seq(0, max(arbolado$circ_tronco_cm), by = 25))

# ggsave("pics/3_1_histograma_circ_tronco_bins_30.png", plot = last_plot(), width = 8, height = 6)
```

```{r}
ggplot(arbolado, aes(x = circ_tronco_cm)) +
    geom_histogram(bins = 40, aes(fill = after_stat(count))) +
    scale_fill_gradient(low = "blue", high = "red") +
    labs(title = "Histograma de Circunferencia del Tronco (Bins = 40)", x = "Circunferencia del Tronco (cm)", y = "Frecuencia") +
    scale_x_continuous(breaks = seq(0, max(arbolado$circ_tronco_cm), by = 25))

# ggsave("pics/3_1_histograma_circ_tronco_bins_40.png", plot = last_plot(), width = 8, height = 6)
```

```{r}
ggplot(arbolado, aes(x = circ_tronco_cm)) +
    geom_histogram(bins = 50, aes(fill = after_stat(count))) +
    scale_fill_gradient(low = "blue", high = "red") +
    labs(title = "Histograma de Circunferencia del Tronco (Bins = 50)", x = "Circunferencia del Tronco (cm)", y = "Frecuencia") +
    scale_x_continuous(breaks = seq(0, max(arbolado$circ_tronco_cm), by = 25))

# ggsave("pics/3_1_histograma_circ_tronco_bins_50.png", plot = last_plot(), width = 8, height = 6)
```


## Ejercicio 3.2
Repetir el punto 1) pero separando por la clase de la variable inclinación_peligrosa.

```{r}
ggplot(arbolado, aes(x = circ_tronco_cm, fill = factor(inclinacion_peligrosa))) +
    geom_histogram(bins = 10) +
    labs(title = "Histograma de Circunferencia del Tronco por Clase de Inclinacion (Bins = 10)", x = "Circunferencia del Tronco (cm)", y = "Frecuencia") +
    scale_fill_discrete(name = "Inclinacion") +
    scale_x_continuous(breaks = seq(0, max(arbolado$circ_tronco_cm), by = 25))

# ggsave("../pics/3_2_histograma_circ_tronco_separado_por_inclinacion_bins_10.png", plot = last_plot(), width = 8, height = 6)
```

```{r}
ggplot(arbolado, aes(x = circ_tronco_cm, fill = factor(inclinacion_peligrosa))) +
    geom_histogram(bins = 20) +
    labs(title = "Histograma de Circunferencia del Tronco por Clase de Inclinacion (Bins = 20)", x = "Circunferencia del Tronco (cm)", y = "Frecuencia") +
    scale_fill_discrete(name = "Inclinacion") +
    scale_x_continuous(breaks = seq(0, max(arbolado$circ_tronco_cm), by = 25))

# ggsave("../pics/3_2_histograma_circ_tronco_separado_por_inclinacion_bins_20.png", plot = last_plot(), width = 8, height = 6)
```

```{r}
ggplot(arbolado, aes(x = circ_tronco_cm, fill = factor(inclinacion_peligrosa))) +
    geom_histogram(bins = 30) +
    labs(title = "Histograma de Circunferencia del Tronco por Clase de Inclinacion (Bins = 30)", x = "Circunferencia del Tronco (cm)", y = "Frecuencia") +
    scale_fill_discrete(name = "Inclinacion") +
    scale_x_continuous(breaks = seq(0, max(arbolado$circ_tronco_cm), by = 25))

# ggsave("../pics/3_2_histograma_circ_tronco_separado_por_inclinacion_bins_30.png", plot = last_plot(), width = 8, height = 6)
```

```{r}
ggplot(arbolado, aes(x = circ_tronco_cm, fill = factor(inclinacion_peligrosa))) +
    geom_histogram(bins = 40) +
    labs(title = "Histograma de Circunferencia del Tronco por Clase de Inclinacion (Bins = 40)", x = "Circunferencia del Tronco (cm)", y = "Frecuencia") +
    scale_fill_discrete(name = "Inclinacion") +
    scale_x_continuous(breaks = seq(0, max(arbolado$circ_tronco_cm), by = 25))

# ggsave("../pics/3_2_histograma_circ_tronco_separado_por_inclinacion_bins_40.png", plot = last_plot(), width = 8, height = 6)
```

```{r}
ggplot(arbolado, aes(x = circ_tronco_cm, fill = factor(inclinacion_peligrosa))) +
    geom_histogram(bins = 50) +
    labs(title = "Histograma de Circunferencia del Tronco por Clase de Inclinacion (Bins = 50)", x = "Circunferencia del Tronco (cm)", y = "Frecuencia") +
    scale_fill_discrete(name = "Inclinacion") +
    scale_x_continuous(breaks = seq(0, max(arbolado$circ_tronco_cm), by = 25))

# ggsave("../pics/3_2_histograma_circ_tronco_separado_por_inclinacion_bins_50.png", plot = last_plot(), width = 8, height = 6)
```


## Ejercicio 3.3
Crear una nueva variable categórica de nombre circ_tronco_cm_cat a partir circ_tronco_cm, en donde puedan asignarse
solo 4 posibles valores \[muy alto, alto, medio, bajo]. Utilizar la información del punto b para seleccionar los puntos
de corte para cada categoría.

```{r}
arbolado <- read.csv("data/arbolado-mendoza-dataset-train.csv")

# calcula los cuartiles de la variable circ_tronco_cm
percentil_25 <- quantile(arbolado$circ_tronco_cm, 0.25)
percentil_50 <- quantile(arbolado$circ_tronco_cm, 0.50)
percentil_75 <- quantile(arbolado$circ_tronco_cm, 0.75)

cortes <- c(0, percentil_25, percentil_50, percentil_75, max(arbolado$circ_tronco_cm))

etiquetas <- c("bajo", "medio", "alto", "muy alto")

# crea la variable categórica
arbolado$circ_tronco_cm_cat <- cut(arbolado$circ_tronco_cm, breaks = cortes, labels = etiquetas, include.lowest = TRUE)

# muestra las primeras filas del nuevo dataframe
head(arbolado)

```


## Ejercicio 3.4
Guardar el nuevo dataframe bajo el nombre de arbolado-mendoza-dataset-circ_tronco_cm-train.csv

```{r}
write.csv(arbolado, "data/arbolado-mendoza-dataset-circ_tronco_cm-train.csv", row.names = FALSE)
```

# Ejercicio 4: Clasificador Aleatório

## Ejercicio 4.1
Implementar una función que dado un conjunto de observaciones (data.frame) genere una nueva columna de nombre
prediction_prob con un valor aleatorio entre 0 y 1.

```{r}
agregar_prediccion_aleatoria <- function(data) {
  # genera valores aleatorios entre 0 y 1
  prediction_prob <- runif(nrow(data))

  # agrega la columna "prediction_prob" al data.frame
  data$prediction_prob <- prediction_prob

  # devuelve el data.frame con la nueva columna
  return(data)
}
```


```{r}
set.seed(123)  # semilla para reproducibilidad
datos <- read.csv("data/arbolado-mendoza-dataset-train.csv")
datos_con_prediccion <- agregar_prediccion_aleatoria(datos)
print(datos_con_prediccion)
```


## Ejercicio 4.2
Implementar una función de nombre random_classifier, que reciba como parámetro el dataframe generado con anterioridad
y a partir de la columna predictions_prob genere una nueva columna prediction_class bajo el siguiente criterio: `If
predictions_prob > 0.5 then prediction_class=1 else prediction_class=0`

La función deberá devolver el dataframe original junto a la nueva columna generada.

```{r}
random_classifier <- function(data) {
  # crea una nueva columna "prediction_class" basada en "prediction_prob"
  data$prediction_class <- ifelse(data$prediction_prob > 0.5, 1, 0)

  return(data)
}
```

```{r}
datos_con_prediccion <- random_classifier(datos_con_prediccion)
print(datos_con_prediccion)
```

## Ejercicio 4.3
Cargar el archivo arbolado-mendoza-dataset-validation.csv como una data.frame y aplicarle la función random_classifier.

```{r}
data <- read.csv("data/arbolado-mendoza-dataset-validation.csv")
data_con_prediccion <- agregar_prediccion_aleatoria(data)
data_con_prediccion <- random_classifier(data_con_prediccion)
print(data_con_prediccion)
```
## Ejercicio 4.4
A partir de la columna recientemente generada y la columna con la clase (inclinación peligrosa) calcular utilizando
lenguaje R (dplyr) el número de:

1. Número de árboles CON inclinación peligrosa que fueron correctamente predichos como peligrosos por el
  modelo/algoritmo. (True Positive)

2. Número de árboles SIN inclinación peligrosa que fueron correctamente predichos como no peligrosos por el
  modelo. (True Negative)

3. Número de árboles SIN inclinación peligrosa que fueron incorrectamente predichos como peligrosos según el
  modelo. (False Positives)

4. Número de árboles CON inclinación peligrosa que fueron incorrectamente predichos como no peligrosos según el
  modelo. (False Negatives)

El resultado es una tabla que se conoce como matriz de confusión.

# Ejercicio 5: Clasificador por clase Mayoritaria:

## Ejercicio 5.1
Implementar una función de nombre biggerclass_classifier, que reciba como parámetro el dataframe generado con
anterioridad y genere una nueva columna de nombre prediction_class en donde se asigne siempre de la clase mayoritaria

La función deberá devolver el dataframe original junto a la nueva columna generada.

## Ejercicio 5.2
Repetir los puntos 4.c y 4.d pero aplicando la nueva función biggerclass_classifier

# Ejercicio 6

A partir de una matriz de confusión es posible calcular distintas métricas que nos permiten determinar la calidad del
modelo de clasificación.

Utilizar la siguiente imagen como guía crear funciones para calcular: _Accuracy, Precision, Sensitivity, Specificity_ y
calcularlas para las matrices de confusión generadas en los puntos 4 y 5.

# Ejercicio 7: Validación Cruzada (Cross Validation) (k-folds)

La validación cruzada es una técnica para estimar el error de generalización de un algoritmo/modelo de machine learning.
La técnica consiste en (previo realizar una mezcla aleatoria) separar el conjunto de datos en k partes (normalmente
denominadas folds). Luego en la primera iteración se utilizan k-1 partes para entrenar E1 y se utiliza la restante
para test. El proceso se repite por k iteraciones utilizando en cada una diferentes conjuntos de entrenamiento y test.

## Ejercicio 7.1
Crear una función de nombre create_folds() que reciba como parámetro un dataframe y la cantidad de folds y devuelva
una lista de R con la siguiente estructura: `list(Fold1=c(...), Fold2=c(..),... Fold10=c())`. Donde Fold1 va a contender
los índices del dataframe que fueron seleccionados para el primer fold, y así con los demás.

## Ejercicio 7.2
Crear una función de nombre cross_validation() que reciba como parámetro una data frame y un número de folds y entrene
un modelo de árbol de decisión (utilizar paquete rpart) para cada uno de los posibles conjuntos de entrenamiento y
calcule las métricas: _Accuracy, Precision, Sensitivity, Specificity_ para cada uno de los posibles conjuntos de tests.
Devolver media y desviación estándar.